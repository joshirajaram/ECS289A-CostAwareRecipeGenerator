{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c1b6c5-8339-4df8-8bfa-78abf9fd1287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recipes from: ../recipes_data_10k.csv\n",
      "=== FINAL INGREDIENT LIST BUILT ===\n",
      "Total unique ingredients: 3905\n",
      "Saved CSV -> unique_ingredients_final.csv\n",
      "Saved TXT -> unique_ingredients_final.txt\n",
      "\n",
      "Sample of final ingredients:\n",
      "             ingredient\n",
      "       achiote coloring\n",
      "                  acini\n",
      "           acorn squash\n",
      "       active dry yeast\n",
      "           active yeast\n",
      "       adams wheat beer\n",
      "              ajinomoto\n",
      "            alaga syrup\n",
      "          alfalfa honey\n",
      "        alfalfa sprouts\n",
      "          alfredo sauce\n",
      "               all-bran\n",
      "        all-bran cereal\n",
      "            all-purpose\n",
      "all-purpose biscuit mix\n",
      "      all-purpose flour\n",
      "               allspice\n",
      "                 almond\n",
      "            almond bark\n",
      "         almond extract\n",
      "       almond flavoring\n",
      "          almond slices\n",
      "         almond slivers\n",
      "           almond-honey\n",
      "                almonds\n",
      "                 almost\n",
      "                   alum\n",
      "          aluminum foil\n",
      "        american cheese\n",
      " american cheese slices\n",
      "                ammonia\n",
      "              anchovies\n",
      "                anchovy\n",
      "          anchovy paste\n",
      "                  angel\n",
      "        angel food cake\n",
      "  angel food cake cubes\n",
      "    angel food cake mix\n",
      "       angel hair pasta\n",
      "                  anise\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "\n",
    "def safe_literal_eval(x):\n",
    "    \"\"\"Safely parse a string like \"['salt', 'pepper']\" into a Python list.\"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def clean_and_normalize(token: str):\n",
    "    \"\"\"\n",
    "    Full cleaning + normalization pipeline for a single NER token.\n",
    "\n",
    "    Returns:\n",
    "      - final ingredient string, or\n",
    "      - None if this should be discarded.\n",
    "    \"\"\"\n",
    "    if not isinstance(token, str):\n",
    "        return None\n",
    "\n",
    "    # Basic normalize\n",
    "    t = token.strip().lower()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Remove leading possessive: \"'s applesauce\" -> \"applesauce\"\n",
    "    t = re.sub(r\"^['`\\\"]?s\\s+\", \"\", t)\n",
    "\n",
    "    # Strip surrounding punctuation and commas\n",
    "    t = t.strip(\" ,.;:()[]{}\\\"'\")\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "\n",
    "    # Drop tokens with no letters at all (only symbols/numbers)\n",
    "    if not re.search(r\"[a-z]\", t):\n",
    "        return None\n",
    "\n",
    "    # Strip common prefixes:\n",
    "    #   \"additional parsley\" -> \"parsley\"\n",
    "    #   \"any kind blueberries\" -> \"blueberries\"\n",
    "    #   \"some oil\" -> \"oil\"\n",
    "    #   \"your favorite salsa\" -> \"salsa\"\n",
    "    prefixes = [\n",
    "        \"additional \",\n",
    "        \"another \",\n",
    "        \"any kind \",\n",
    "        \"any \",\n",
    "        \"some \",\n",
    "        \"your favorite \",\n",
    "        \"amount \",\n",
    "    ]\n",
    "    for p in prefixes:\n",
    "        if t.startswith(p):\n",
    "            t = t[len(p):].strip()\n",
    "            break\n",
    "\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Handle \"with ...\" / \"without ...\":\n",
    "    #   \"with juice\" -> \"juice\"\n",
    "    #   \"without sugar\" -> \"sugar\"\n",
    "    if t.startswith(\"with \") or t.startswith(\"without \"):\n",
    "        parts = t.split(maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            t = parts[1].strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Remove descriptor suffixes like \" washed\", \" drained\", \" prepared\"\n",
    "    for suffix in (\" washed\", \" drained\", \" prepared\"):\n",
    "        if t.endswith(suffix):\n",
    "            t = t[: -len(suffix)].strip()\n",
    "\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Handle \"favorite X\" anywhere in the phrase:\n",
    "    #   \"favorite chicken\" -> \"chicken\"\n",
    "    #   \"sack favorite tortilla\" -> \"tortilla\"\n",
    "    m = re.search(r\"\\bfavorite\\s+(.+)$\", t)\n",
    "    if m:\n",
    "        t = m.group(1).strip()\n",
    "\n",
    "    # Special case cleanups / normalizations\n",
    "    special_fixes = {\n",
    "        \"xxxx sugar\": \"sugar\",\n",
    "        \"young carrots\": \"carrots\",\n",
    "        \"acorn\": \"acorn squash\",\n",
    "    }\n",
    "    if t in special_fixes:\n",
    "        t = special_fixes[t]\n",
    "\n",
    "    # Explicitly remove AccentÂ® brand and variants\n",
    "    accent_variants = {\n",
    "        \"accent\",\n",
    "        \"accent salt\",\n",
    "        \"accent seasoning\",\n",
    "        \"accent seasonings\",\n",
    "    }\n",
    "    if t in accent_variants or t.startswith(\"accent \"):\n",
    "        return None\n",
    "\n",
    "    # Hard blacklist for obvious non-ingredients / junk\n",
    "    blacklist_exact = {\n",
    "        \"young groundhog\",\n",
    "        \"favorite\",\n",
    "        \"your favorite\",\n",
    "        \"amount\",\n",
    "        \"equal amount\",\n",
    "    }\n",
    "    if t in blacklist_exact:\n",
    "        return None\n",
    "\n",
    "    # Descriptor words that are not ingredients by themselves\n",
    "    descriptor_words = {\n",
    "        \"washed\", \"drained\", \"fresh\", \"cold\", \"hot\", \"warm\",\n",
    "        \"optional\", \"prepared\", \"chopped\", \"sliced\", \"diced\",\n",
    "        \"cooked\", \"uncooked\", \"raw\", \"frozen\", \"thawed\",\n",
    "        \"ripe\", \"lean\", \"boneless\", \"skinless\",\n",
    "        \"whole\", \"large\", \"small\", \"medium\",\n",
    "        \"fine\", \"coarse\", \"thick\", \"thin\",\n",
    "        \"regular\", \"lite\", \"low-fat\", \"nonfat\", \"fat-free\",\n",
    "    }\n",
    "    if t in descriptor_words:\n",
    "        return None\n",
    "\n",
    "    # VERY IMPORTANT: drop single-letter tokens like \"a\"\n",
    "    if len(t) <= 1:\n",
    "        return None\n",
    "\n",
    "    # Final trailing comma + whitespace cleanup\n",
    "    t = re.sub(r\",+$\", \"\", t).strip()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Input file with NER column\n",
    "    recipes_csv = \"../recipes_data_10k.csv\"\n",
    "\n",
    "    # Output files\n",
    "    out_csv = \"unique_ingredients_final.csv\"\n",
    "    out_txt = \"unique_ingredients_final.txt\"\n",
    "\n",
    "    print(f\"Loading recipes from: {recipes_csv}\")\n",
    "    df = pd.read_csv(recipes_csv)\n",
    "\n",
    "    if \"NER\" not in df.columns:\n",
    "        raise ValueError(\"Expected a column named 'NER' in recipes_data_10k.csv\")\n",
    "\n",
    "    # Parse NER column into Python lists\n",
    "    df[\"NER_list\"] = df[\"NER\"].apply(safe_literal_eval)\n",
    "\n",
    "    # Collect cleaned + normalized unique ingredients\n",
    "    unique = set()\n",
    "    for ner_list in df[\"NER_list\"]:\n",
    "        for tok in ner_list:\n",
    "            cleaned = clean_and_normalize(tok)\n",
    "            if cleaned:\n",
    "                unique.add(cleaned)\n",
    "\n",
    "    # Sort and convert to DataFrame\n",
    "    unique_list = sorted(unique)\n",
    "    out_df = pd.DataFrame({\"ingredient\": unique_list})\n",
    "\n",
    "    # Save CSV\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Save TXT (one per line)\n",
    "    with open(out_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ing in unique_list:\n",
    "            f.write(ing + \"\\n\")\n",
    "\n",
    "    print(\"=== FINAL INGREDIENT LIST BUILT ===\")\n",
    "    print(f\"Total unique ingredients: {len(unique_list)}\")\n",
    "    print(f\"Saved CSV -> {out_csv}\")\n",
    "    print(f\"Saved TXT -> {out_txt}\")\n",
    "    print(\"\\nSample of final ingredients:\")\n",
    "    print(out_df.head(40).to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9655d4-14e2-4f6c-9a7a-82eb3a16432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3182, 723, 'matched_ingredients.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Load files\n",
    "ing = pd.read_csv('../ingredients.csv')\n",
    "uniq = pd.read_csv('unique_ingredients_final.csv')\n",
    "\n",
    "# Convert to lowercase\n",
    "descriptions = ing['Description'].astype(str).str.lower()\n",
    "unique_names = uniq.iloc[:,0].astype(str).str.lower()\n",
    "\n",
    "matches = []\n",
    "unmatched = []\n",
    "\n",
    "for name in unique_names:\n",
    "    result = process.extractOne(name, descriptions, scorer=fuzz.partial_ratio)\n",
    "    if result:\n",
    "        match, score, idx = result\n",
    "        if score > 70:\n",
    "            row = ing.iloc[idx]\n",
    "            matches.append({\n",
    "                'Unique Ingredient': name,\n",
    "                'Matched Description': row['Description'],\n",
    "                'Carbohydrate': row.get('Data.Carbohydrate', None),\n",
    "                'Fat.Total Lipid': row.get('Data.Fat.Total Lipid', None),\n",
    "                'Protein': row.get('Data.Protein', None),\n",
    "                'Score': score\n",
    "            })\n",
    "        else:\n",
    "            unmatched.append(name)\n",
    "    else:\n",
    "        unmatched.append(name)\n",
    "\n",
    "# Convert results to dataframe\n",
    "out_df = pd.DataFrame(matches)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'matched_ingredients.csv'\n",
    "out_df.to_csv(output_path, index=False)\n",
    "\n",
    "(len(matches), len(unmatched), output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

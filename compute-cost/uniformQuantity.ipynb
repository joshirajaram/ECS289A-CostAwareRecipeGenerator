{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7668e7-d6c9-44d3-bb8a-b0509a70095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7fcf45-1ac4-48d9-9d2d-74ced2a4ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ingredient universe after extra cleaning: 3896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/rpdw29150sv1pkb3k9rdskyr0000gn/T/ipykernel_31437/3002663324.py:18: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask_bad = final_ing_df[\"ingredient\"].str.contains(bad_pattern, case=False, na=False)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"recipes_data_10k.csv\")\n",
    "\n",
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "df[\"ing_list\"] = df[\"ingredients\"].apply(safe_literal_eval)\n",
    "df[\"ner_list\"] = df[\"NER\"].apply(safe_literal_eval)\n",
    "\n",
    "# ðŸ‘‰ Load the final cleaned + normalized ingredient universe\n",
    "# ðŸ‘‰ Load the final cleaned + normalized ingredient universe\n",
    "final_ing_df = pd.read_csv(\"unique_ingredients_final.csv\")\n",
    "\n",
    "# Drop obviously non-ingredient patterns like \"choice\", \"favorite\", \"amount\"\n",
    "bad_pattern = r\"(choice|favorite|equal amount)\"\n",
    "mask_bad = final_ing_df[\"ingredient\"].str.contains(bad_pattern, case=False, na=False)\n",
    "final_ing_df = final_ing_df[~mask_bad]\n",
    "\n",
    "final_ingredients = final_ing_df[\"ingredient\"].astype(str).tolist()\n",
    "final_ingredient_set = set(final_ingredients)\n",
    "\n",
    "print(\"Final ingredient universe after extra cleaning:\", len(final_ingredients))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb47d17-66d1-4f18-9ca0-7577a93377d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_ner_token(token):\n",
    "    \"\"\"\n",
    "    Clean and normalize a raw NER token into a canonical ingredient name.\n",
    "    This should match the logic used in UniqueIngredients.ipynb.\n",
    "    \"\"\"\n",
    "    if not isinstance(token, str):\n",
    "        return None\n",
    "\n",
    "    t = token.strip().lower()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Remove leading possessive: \"'s applesauce\" -> \"applesauce\"\n",
    "    t = re.sub(r\"^['`\\\"]?s\\s+\", \"\", t)\n",
    "\n",
    "    # Strip surrounding punctuation and commas\n",
    "    t = t.strip(\" ,.;:()[]{}\\\"'\")\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "\n",
    "    # Drop tokens with no letters at all\n",
    "    if not re.search(r\"[a-z]\", t):\n",
    "        return None\n",
    "\n",
    "    # Strip common prefixes:\n",
    "    #   \"additional parsley\" -> \"parsley\"\n",
    "    #   \"any kind blueberries\" -> \"blueberries\"\n",
    "    #   \"some oil\" -> \"oil\"\n",
    "    #   \"your favorite salsa\" -> \"salsa\"\n",
    "    prefixes = [\n",
    "        \"additional \",\n",
    "        \"another \",\n",
    "        \"any kind \",\n",
    "        \"any \",\n",
    "        \"some \",\n",
    "        \"your favorite \",\n",
    "        \"amount \",\n",
    "    ]\n",
    "    for p in prefixes:\n",
    "        if t.startswith(p):\n",
    "            t = t[len(p):].strip()\n",
    "            break\n",
    "\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Handle \"with ...\" / \"without ...\":\n",
    "    #   \"with juice\" -> \"juice\"\n",
    "    #   \"without sugar\" -> \"sugar\"\n",
    "    if t.startswith(\"with \") or t.startswith(\"without \"):\n",
    "        parts = t.split(maxsplit=1)\n",
    "        if len(parts) == 2:\n",
    "            t = parts[1].strip()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Remove descriptor suffixes like \" washed\", \" drained\", \" prepared\"\n",
    "    for suffix in (\" washed\", \" drained\", \" prepared\"):\n",
    "        if t.endswith(suffix):\n",
    "            t = t[: -len(suffix)].strip()\n",
    "\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    # Handle \"favorite X\" anywhere in the phrase:\n",
    "    #   \"favorite chicken\" -> \"chicken\"\n",
    "    #   \"sack favorite tortilla\" -> \"tortilla\"\n",
    "    m = re.search(r\"\\bfavorite\\s+(.+)$\", t)\n",
    "    if m:\n",
    "        t = m.group(1).strip()\n",
    "\n",
    "    # Special case cleanups / normalizations\n",
    "    special_fixes = {\n",
    "        \"xxxx sugar\": \"sugar\",\n",
    "        \"young carrots\": \"carrots\",\n",
    "        \"acorn\": \"acorn squash\",\n",
    "    }\n",
    "    if t in special_fixes:\n",
    "        t = special_fixes[t]\n",
    "\n",
    "    # Explicitly remove Accent brand variants\n",
    "    accent_variants = {\n",
    "        \"accent\",\n",
    "        \"accent salt\",\n",
    "        \"accent seasoning\",\n",
    "        \"accent seasonings\",\n",
    "    }\n",
    "    if t in accent_variants or t.startswith(\"accent \"):\n",
    "        return None\n",
    "\n",
    "    # Hard blacklist for obvious non-ingredients / junk\n",
    "    blacklist_exact = {\n",
    "        \"young groundhog\",\n",
    "        \"favorite\",\n",
    "        \"your favorite\",\n",
    "        \"amount\",\n",
    "        \"equal amount\",\n",
    "    }\n",
    "    if t in blacklist_exact:\n",
    "        return None\n",
    "\n",
    "    # Descriptor words that are not ingredients by themselves\n",
    "    descriptor_words = {\n",
    "        \"washed\", \"drained\", \"fresh\", \"cold\", \"hot\", \"warm\",\n",
    "        \"optional\", \"prepared\", \"chopped\", \"sliced\", \"diced\",\n",
    "        \"cooked\", \"uncooked\", \"raw\", \"frozen\", \"thawed\",\n",
    "        \"ripe\", \"lean\", \"boneless\", \"skinless\",\n",
    "        \"whole\", \"large\", \"small\", \"medium\",\n",
    "        \"fine\", \"coarse\", \"thick\", \"thin\",\n",
    "        \"regular\", \"lite\", \"low-fat\", \"nonfat\", \"fat-free\",\n",
    "    }\n",
    "    if t in descriptor_words:\n",
    "        return None\n",
    "\n",
    "    # Skip single-character garbage\n",
    "    if len(t) <= 1:\n",
    "        return None\n",
    "\n",
    "    # Final trailing commas/whitespace cleanup\n",
    "    t = re.sub(r\",+$\", \"\", t).strip()\n",
    "    if not t:\n",
    "        return None\n",
    "\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b66e5b-a98d-46b2-80f4-5007c5517f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_aliases = {\n",
    "    'tsp': 'tsp', 'tsps': 'tsp', 'tsp.': 'tsp', 'teaspoon': 'tsp', 'teaspoons': 'tsp',\n",
    "    'tbsp': 'tbsp', 'tbsp.': 'tbsp', 'tbsps': 'tbsp', 'tablespoon': 'tbsp', 'tablespoons': 'tbsp',\n",
    "    'c': 'cup', 'c.': 'cup', 'cup': 'cup', 'cups': 'cup',\n",
    "    'pt': 'pt', 'pt.': 'pt', 'pint': 'pt', 'pints': 'pt',\n",
    "    'qt': 'qt', 'qt.': 'qt', 'quart': 'qt', 'quarts': 'qt',\n",
    "    'oz': 'oz', 'oz.': 'oz', 'ounce': 'oz', 'ounces': 'oz',\n",
    "    'lb': 'lb', 'lb.': 'lb', 'lbs': 'lb', 'lbs.': 'lb', 'pound': 'lb', 'pounds': 'lb',\n",
    "    'g': 'g', 'g.': 'g', 'gram': 'g', 'grams': 'g',\n",
    "    'kg': 'kg', 'kg.': 'kg', 'kilogram': 'kg', 'kilograms': 'kg',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51c3831-acfd-4671-81c3-bc919efec2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grams_per_unit = {\n",
    "    'tsp': 5.0,\n",
    "    'tbsp': 15.0,\n",
    "    'cup': 240.0,\n",
    "    'pt': 473.0,\n",
    "    'qt': 946.0,\n",
    "    'oz': 28.3495,\n",
    "    'lb': 453.592,\n",
    "    'g': 1.0,\n",
    "    'kg': 1000.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6970530-b70c-4aae-a443-707f9ffc201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_leading_quantity(s: str):\n",
    "    \"\"\"\n",
    "    Extract a leading quantity like:\n",
    "      - '1'\n",
    "      - '1/2'\n",
    "      - '1 1/2'\n",
    "      - '1-1/2'\n",
    "    and return (float_qty, raw_qty_str, rest_of_string)\n",
    "    \"\"\"\n",
    "    s = s.strip().lower()\n",
    "    m = re.match(r'(\\d+/\\d+|\\d+(?:\\s+\\d+/\\d+|\\s*-\\s*\\d+/\\d+)?)', s)\n",
    "    if not m:\n",
    "        return None, None, s\n",
    "    qty_str = m.group(1)\n",
    "    rest = s[m.end():].lstrip()\n",
    "\n",
    "    def frac_to_float(fs: str) -> float:\n",
    "        # handle things like \"1 1/2\" or \"1-1/2\"\n",
    "        fs = fs.replace('-', ' ')\n",
    "        parts = fs.split()\n",
    "        total = 0.0\n",
    "        for p in parts:\n",
    "            if '/' in p:\n",
    "                num, den = p.split('/')\n",
    "                total += float(num) / float(den)\n",
    "            else:\n",
    "                total += float(p)\n",
    "        return total\n",
    "\n",
    "    try:\n",
    "        qty = frac_to_float(qty_str)\n",
    "    except Exception:\n",
    "        qty = None\n",
    "\n",
    "    return qty, qty_str, rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d24eef-b7a0-4927-8d2d-1a3e5685ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grams(ing_text: str):\n",
    "    \"\"\"\n",
    "    Approximate the weight in grams for a single ingredient line.\n",
    "    Returns a float (grams) or None if completely unparseable.\n",
    "    \"\"\"\n",
    "    s = ing_text.lower()\n",
    "    qty, qty_str, rest = parse_leading_quantity(s)\n",
    "    grams = None\n",
    "\n",
    "    if qty is not None:\n",
    "        # Try to read a unit immediately after the quantity\n",
    "        m = re.match(r'([a-z]+\\.?)', rest)\n",
    "        unit_norm = None\n",
    "        if m:\n",
    "            unit_raw = m.group(1)\n",
    "            unit_norm = unit_aliases.get(unit_raw)\n",
    "\n",
    "        if unit_norm not in grams_per_unit:\n",
    "            unit_norm = None\n",
    "\n",
    "        # Case like \"1 (12 oz.) can ...\" (nested weight inside)\n",
    "        if grams is None:\n",
    "            m2 = re.search(\n",
    "                r'(\\d+(?:\\.\\d+)?)\\s*(oz\\.?|ounce[s]?|g\\.?|gram[s]?|kg\\.?|kilogram[s]?|lb\\.?|pound[s]?)',\n",
    "                rest\n",
    "            )\n",
    "            if m2:\n",
    "                inner_qty = float(m2.group(1))\n",
    "                unit_raw2 = m2.group(2).replace('.', '')\n",
    "                if unit_raw2.startswith(('oz', 'ou')):\n",
    "                    unit_norm2 = 'oz'\n",
    "                elif unit_raw2.startswith('g'):\n",
    "                    unit_norm2 = 'g'\n",
    "                elif unit_raw2.startswith(('kg', 'ki')):\n",
    "                    unit_norm2 = 'kg'\n",
    "                elif unit_raw2.startswith(('lb', 'po')):\n",
    "                    unit_norm2 = 'lb'\n",
    "                else:\n",
    "                    unit_norm2 = None\n",
    "\n",
    "                if unit_norm2 and unit_norm2 in grams_per_unit:\n",
    "                    grams = inner_qty * grams_per_unit[unit_norm2] * (qty if qty not in (None, 0) else 1.0)\n",
    "\n",
    "        # Simple unit (cup, tsp, Tbsp, etc.)\n",
    "        if grams is None and unit_norm in grams_per_unit:\n",
    "            grams = qty * grams_per_unit[unit_norm]\n",
    "\n",
    "        # Fallback heuristics if we still have nothing\n",
    "        if grams is None:\n",
    "            if 'egg' in rest:\n",
    "                grams = qty * 50.0\n",
    "            elif 'clove' in rest and 'garlic' in rest:\n",
    "                grams = qty * 5.0\n",
    "            elif 'can ' in rest or 'can of' in rest:\n",
    "                grams = qty * 400.0\n",
    "            elif 'package' in rest or 'pkg' in rest:\n",
    "                grams = qty * 300.0\n",
    "            elif 'slice' in rest:\n",
    "                grams = qty * 30.0\n",
    "            else:\n",
    "                grams = qty * 50.0  # generic guess\n",
    "\n",
    "    else:\n",
    "        # No leading qty, but maybe \"16 oz. cheese\"\n",
    "        m3 = re.search(\n",
    "            r'(\\d+(?:\\.\\d+)?)\\s*(oz\\.?|ounce[s]?|g\\.?|gram[s]?|kg\\.?|kilogram[s]?|lb\\.?|pound[s]?)',\n",
    "            s\n",
    "        )\n",
    "        if m3:\n",
    "            q = float(m3.group(1))\n",
    "            unit_raw3 = m3.group(2).strip('.')\n",
    "            if unit_raw3.startswith(('oz', 'ou')):\n",
    "                unit_norm3 = 'oz'\n",
    "            elif unit_raw3.startswith('g'):\n",
    "                unit_norm3 = 'g'\n",
    "            elif unit_raw3.startswith(('kg', 'ki')):\n",
    "                unit_norm3 = 'kg'\n",
    "            elif unit_raw3.startswith(('lb', 'po')):\n",
    "                unit_norm3 = 'lb'\n",
    "            else:\n",
    "                unit_norm3 = None\n",
    "\n",
    "            if unit_norm3 and unit_norm3 in grams_per_unit:\n",
    "                grams = q * grams_per_unit[unit_norm3]\n",
    "\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc0420a-f267-4dee-8e3f-18122e66d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example grams_map entry:\n",
      " {'bite size shredded rice biscuits': 240.0, 'vanilla': 120.0, 'brown sugar': 2.5, 'nuts': 120.0, 'milk': 30.0, 'butter': 840.0}\n"
     ]
    }
   ],
   "source": [
    "def compute_recipe_grams_row(ing_texts, ner_names):\n",
    "    grams_map = {}\n",
    "    for txt, name in zip(ing_texts, ner_names):\n",
    "        cleaned_name = clean_ner_token(name)\n",
    "        if cleaned_name is None:\n",
    "            continue\n",
    "\n",
    "        # Only keep ingredients that are in the final normalized universe\n",
    "        if cleaned_name not in final_ingredient_set:\n",
    "            continue\n",
    "\n",
    "        g = parse_grams(txt)\n",
    "        if g is None:\n",
    "            continue\n",
    "\n",
    "        grams_map[cleaned_name] = grams_map.get(cleaned_name, 0.0) + g\n",
    "\n",
    "    return grams_map\n",
    "\n",
    "df[\"grams_map\"] = [\n",
    "    compute_recipe_grams_row(ings, ners)\n",
    "    for ings, ners in zip(df[\"ing_list\"], df[\"ner_list\"])\n",
    "]\n",
    "\n",
    "print(\"Example grams_map entry:\\n\", df[\"grams_map\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8982d8f5-cf4d-4356-80c2-e4234b92662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded CSV saved to: recipes_ingredients_grams_matrix.csv\n",
      "Columns: 3896\n"
     ]
    }
   ],
   "source": [
    "# Use the final cleaned ingredient universe + consistent order\n",
    "all_ingredients = final_ingredients\n",
    "\n",
    "output_path = \"recipes_ingredients_grams_matrix.csv\"\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Header\n",
    "    header = [\"title\"] + all_ingredients\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # Rows\n",
    "    for title, grams_map in zip(df[\"title\"], df[\"grams_map\"]):\n",
    "        row = [title]\n",
    "        for ing in all_ingredients:\n",
    "            val = grams_map.get(ing, 0.0)\n",
    "\n",
    "            # ðŸ”¥ rounding to whole grams\n",
    "            val = round(val)\n",
    "            # if you want decimals instead:\n",
    "            # val = round(val, 2)\n",
    "\n",
    "            row.append(val)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Rounded CSV saved to:\", output_path)\n",
    "print(\"Columns:\", len(all_ingredients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f96737-bd94-4525-93b0-30c6fbe9b00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
